{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = ('/Users/carolinesklaver/Desktop/Capstone/NHANES/data/csv_data/')\n",
    "\n",
    "import os\n",
    "os.chdir(path)\n",
    "SEED = 42\n",
    "\n",
    "# target binary feature\n",
    "target = 'depressed'\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "#continuous features\n",
    "cont = ['#_ppl_household', 'age', 'triglyceride','caffeine', 'lifetime_partners',\n",
    "       'glycohemoglobin', 'CRP', 'tot_cholesterol','systolic_BP','diastolic_BP', 'BMI', 'waist_C', '#meals_fast_food',\n",
    "       'min_sedetary', 'bone_mineral_density']\n",
    "\n",
    "# categorical features\n",
    "cat = ['race_ethnicity', 'edu_level', 'gender', 'marital_status', 'annual_HI',\n",
    "       'doc_diabetes', 'how_healthy_diet', 'used_CMH',\n",
    "       'health_insurance', 'doc_asthma', 'doc_overweight', 'doc_arthritis',\n",
    "       'doc_CHF', 'doc_CHD', 'doc_heart_attack', 'doc_stroke',\n",
    "       'doc_chronic_bronchitis', 'doc_liver_condition', 'doc_thyroid_problem',\n",
    "       'doc_cancer', 'difficult_seeing', 'doc_kidney', 'broken_hip',\n",
    "       'doc_osteoporosis', 'vigorous_activity', 'moderate_activity',\n",
    "       'doc_sleeping_disorder', 'smoker', 'sexual_orientation',\n",
    "       'alcoholic','herpes_2', 'HIV', 'doc_HPV','difficult_hearing', 'doc_COPD']\n",
    "\n",
    "# multi-class features\n",
    "cat_encode = ['race_ethnicity', 'edu_level', 'gender', 'marital_status', 'annual_HI','how_healthy_diet',\n",
    "              'sexual_orientation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_mlp_impute = pd.read_csv('df_progressive_mlp_2.csv')\n",
    "df_mlp_impute.drop(['year'],axis=1, inplace=True)\n",
    "df_mlp_impute.drop(['SEQN'],axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Function to One-hot-encode the categorical features\n",
    "def one_hot_encode(df):\n",
    "    cols = df.columns\n",
    "    e_cols = list(set(cols).intersection(set(cat_encode)))\n",
    "    df_encode = pd.get_dummies(df, columns=e_cols)\n",
    "\n",
    "    return (df_encode)\n",
    "\n",
    "df = one_hot_encode(df_mlp_impute)\n",
    "\n",
    "# divide into training and testing\n",
    "# df_raw_train, df_raw_test = train_test_split(df, test_size=0.2, random_state=SEED)\n",
    "\n",
    "# # Reset the index\n",
    "# df_raw_train, df_raw_test = df_raw_train.reset_index(drop=True), df_raw_test.reset_index(drop=True)\n",
    "\n",
    "# # Make a copy of df_raw_train\n",
    "# df_train = df_raw_train.copy(deep=True)\n",
    "\n",
    "# # Make a copy of df_raw_test\n",
    "# df_test = df_raw_test.copy(deep=True)\n",
    "\n",
    "# df = pd.concat([df_train, df_test], sort=False)\n",
    "\n",
    "# get the name of the features\n",
    "features = np.setdiff1d(df.columns, [target])\n",
    "\n",
    "\n",
    "# # Get the feature matrix\n",
    "# X_train = df_train[features].to_numpy()\n",
    "# X_test = df_test[features].to_numpy()\n",
    "\n",
    "# # Get the target vector\n",
    "# y_train = df_train[target].astype(int).to_numpy()\n",
    "# y_test = df_test[target].astype(int).to_numpy()\n",
    "\n",
    "\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# # The StandardScaler\n",
    "# ss = StandardScaler()\n",
    "\n",
    "# # Standardize the training data\n",
    "# X_train = ss.fit_transform(X_train)\n",
    "\n",
    "# # Standardize the testing data\n",
    "# X_test = ss.transform(X_test)\n",
    "\n",
    "\n",
    "# input_size = len(df_train.columns)-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>depressed</th>\n",
       "      <th>#_ppl_household</th>\n",
       "      <th>age</th>\n",
       "      <th>caffeine</th>\n",
       "      <th>doc_diabetes</th>\n",
       "      <th>used_CMH</th>\n",
       "      <th>health_insurance</th>\n",
       "      <th>doc_asthma</th>\n",
       "      <th>doc_overweight</th>\n",
       "      <th>doc_arthritis</th>\n",
       "      <th>...</th>\n",
       "      <th>marital_status_5.0</th>\n",
       "      <th>marital_status_6.0</th>\n",
       "      <th>how_healthy_diet_1.0</th>\n",
       "      <th>how_healthy_diet_2.0</th>\n",
       "      <th>how_healthy_diet_3.0</th>\n",
       "      <th>how_healthy_diet_4.0</th>\n",
       "      <th>how_healthy_diet_5.0</th>\n",
       "      <th>how_healthy_diet_9.0</th>\n",
       "      <th>gender_1.0</th>\n",
       "      <th>gender_2.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>1.300000e+01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>2.600000e+02</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>1.420000e+02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>5.397605e-79</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>5.397605e-79</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 84 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   depressed  #_ppl_household   age      caffeine  doc_diabetes  used_CMH  \\\n",
       "0        0.0              4.0  44.0  1.300000e+01           0.0       0.0   \n",
       "1        0.0              2.0  70.0  2.600000e+02           1.0       0.0   \n",
       "2        0.0              2.0  73.0  1.420000e+02           0.0       0.0   \n",
       "3        0.0              3.0  18.0  5.397605e-79           0.0       0.0   \n",
       "4        0.0              3.0  19.0  5.397605e-79           0.0       0.0   \n",
       "\n",
       "   health_insurance  doc_asthma  doc_overweight  doc_arthritis  ...  \\\n",
       "0               1.0         0.0             0.0            0.0  ...   \n",
       "1               1.0         0.0             0.0            0.0  ...   \n",
       "2               1.0         0.0             1.0            0.0  ...   \n",
       "3               1.0         1.0             1.0            0.0  ...   \n",
       "4               1.0         0.0             0.0            0.0  ...   \n",
       "\n",
       "   marital_status_5.0  marital_status_6.0  how_healthy_diet_1.0  \\\n",
       "0                   0                   0                     0   \n",
       "1                   0                   0                     0   \n",
       "2                   0                   0                     0   \n",
       "3                   1                   0                     0   \n",
       "4                   1                   0                     0   \n",
       "\n",
       "   how_healthy_diet_2.0  how_healthy_diet_3.0  how_healthy_diet_4.0  \\\n",
       "0                     0                     1                     0   \n",
       "1                     1                     0                     0   \n",
       "2                     0                     1                     0   \n",
       "3                     0                     1                     0   \n",
       "4                     0                     1                     0   \n",
       "\n",
       "   how_healthy_diet_5.0  how_healthy_diet_9.0  gender_1.0  gender_2.0  \n",
       "0                     0                     0           0           1  \n",
       "1                     0                     0           1           0  \n",
       "2                     0                     0           1           0  \n",
       "3                     0                     0           0           1  \n",
       "4                     0                     0           1           0  \n",
       "\n",
       "[5 rows x 84 columns]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we have df which is encoded, lets get the testing and validation sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# divide into training and testing\n",
    "df_raw_train, df_raw_test = train_test_split(df, test_size=0.2, random_state=SEED)\n",
    "# Reset the index\n",
    "df_raw_train, df_raw_test = df_raw_train.reset_index(drop=True), df_raw_test.reset_index(drop=True)\n",
    "\n",
    "# Make a copy of df_raw_train\n",
    "df_train = df_raw_train.copy(deep=True)\n",
    "# Make a copy of df_raw_test\n",
    "df_test = df_raw_test.copy(deep=True)\n",
    "\n",
    "\n",
    "# Divide the training data into training (80%) and validation (20%)\n",
    "df_train, df_valid = train_test_split(df_train, train_size=0.8, random_state=42, stratify=df_train[target])\n",
    "# Reset the index\n",
    "df_train, df_valid = df_train.reset_index(drop=True), df_valid.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/opt/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py:965: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/opt/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py:965: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "# now we have df_train, df_valid, df_test\n",
    "# let's standardize the testing and validation\n",
    "# separate X_test, y_test and X_val, y_val\n",
    "X_test = df_test[features]\n",
    "y_test = df_test[target]\n",
    "\n",
    "X_val = df_valid[features]\n",
    "y_val = df_valid[target]\n",
    "\n",
    "# Scale the test and valid features\n",
    "X_test[cont] = ss.fit_transform(X_test[cont])\n",
    "X_test.columns = X_test.keys().tolist()\n",
    "\n",
    "X_val[cont] = ss.fit_transform(X_val[cont])\n",
    "X_val.columns = X_val.keys().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#_ppl_household</th>\n",
       "      <th>#meals_fast_food</th>\n",
       "      <th>BMI</th>\n",
       "      <th>CRP</th>\n",
       "      <th>HIV</th>\n",
       "      <th>age</th>\n",
       "      <th>alcoholic</th>\n",
       "      <th>annual_HI_1.0</th>\n",
       "      <th>annual_HI_10.0</th>\n",
       "      <th>annual_HI_11.0</th>\n",
       "      <th>...</th>\n",
       "      <th>sexual_orientation_3.0</th>\n",
       "      <th>sexual_orientation_4.0</th>\n",
       "      <th>sexual_orientation_5.0</th>\n",
       "      <th>smoker</th>\n",
       "      <th>systolic_BP</th>\n",
       "      <th>tot_cholesterol</th>\n",
       "      <th>triglyceride</th>\n",
       "      <th>used_CMH</th>\n",
       "      <th>vigorous_activity</th>\n",
       "      <th>waist_C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.635930</td>\n",
       "      <td>-0.836587</td>\n",
       "      <td>0.164802</td>\n",
       "      <td>-0.512095</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.360626</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.127785</td>\n",
       "      <td>0.957942</td>\n",
       "      <td>0.591330</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.371829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.722875</td>\n",
       "      <td>-0.411272</td>\n",
       "      <td>-0.753192</td>\n",
       "      <td>1.882147</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.338135</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.346085</td>\n",
       "      <td>1.227433</td>\n",
       "      <td>0.001512</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.686526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.133174</td>\n",
       "      <td>0.439359</td>\n",
       "      <td>2.630189</td>\n",
       "      <td>-0.079240</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.293689</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.206601</td>\n",
       "      <td>1.031439</td>\n",
       "      <td>0.168181</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.309155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.133174</td>\n",
       "      <td>-0.095377</td>\n",
       "      <td>-1.201313</td>\n",
       "      <td>0.276345</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.656653</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.196809</td>\n",
       "      <td>-0.120023</td>\n",
       "      <td>-0.084354</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.033331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.456528</td>\n",
       "      <td>-0.411272</td>\n",
       "      <td>-1.415947</td>\n",
       "      <td>-0.379657</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.723590</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.673535</td>\n",
       "      <td>0.075970</td>\n",
       "      <td>-0.717249</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.278487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5012</th>\n",
       "      <td>-1.312576</td>\n",
       "      <td>-0.411272</td>\n",
       "      <td>1.615029</td>\n",
       "      <td>0.262518</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.072704</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.527114</td>\n",
       "      <td>-0.340516</td>\n",
       "      <td>0.963283</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.141732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5013</th>\n",
       "      <td>-1.312576</td>\n",
       "      <td>-0.430966</td>\n",
       "      <td>-0.474749</td>\n",
       "      <td>0.295462</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.665293</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.199665</td>\n",
       "      <td>0.394460</td>\n",
       "      <td>0.171586</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.599046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5014</th>\n",
       "      <td>-0.722875</td>\n",
       "      <td>-0.836587</td>\n",
       "      <td>-0.835855</td>\n",
       "      <td>0.063354</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.603567</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.127785</td>\n",
       "      <td>0.013322</td>\n",
       "      <td>-0.022111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.483226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5015</th>\n",
       "      <td>-0.722875</td>\n",
       "      <td>0.439359</td>\n",
       "      <td>0.701386</td>\n",
       "      <td>-0.044974</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.360626</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.874184</td>\n",
       "      <td>-0.879498</td>\n",
       "      <td>-0.424213</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.425643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5016</th>\n",
       "      <td>-0.722875</td>\n",
       "      <td>0.864674</td>\n",
       "      <td>-1.080944</td>\n",
       "      <td>-0.469206</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.307540</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.000984</td>\n",
       "      <td>0.051471</td>\n",
       "      <td>-0.039060</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.889826</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5017 rows Ã— 83 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      #_ppl_household  #meals_fast_food       BMI       CRP  HIV       age  \\\n",
       "0            1.635930         -0.836587  0.164802 -0.512095  0.0 -1.360626   \n",
       "1           -0.722875         -0.411272 -0.753192  1.882147  0.0  0.338135   \n",
       "2           -0.133174          0.439359  2.630189 -0.079240  0.0  1.293689   \n",
       "3           -0.133174         -0.095377 -1.201313  0.276345  0.0  0.656653   \n",
       "4            0.456528         -0.411272 -1.415947 -0.379657  0.0 -0.723590   \n",
       "...               ...               ...       ...       ...  ...       ...   \n",
       "5012        -1.312576         -0.411272  1.615029  0.262518  0.0  0.072704   \n",
       "5013        -1.312576         -0.430966 -0.474749  0.295462  0.0  1.665293   \n",
       "5014        -0.722875         -0.836587 -0.835855  0.063354  0.0  0.603567   \n",
       "5015        -0.722875          0.439359  0.701386 -0.044974  0.0 -1.360626   \n",
       "5016        -0.722875          0.864674 -1.080944 -0.469206  0.0 -1.307540   \n",
       "\n",
       "      alcoholic  annual_HI_1.0  annual_HI_10.0  annual_HI_11.0  ...  \\\n",
       "0           0.0              0               0               0  ...   \n",
       "1           0.0              0               0               0  ...   \n",
       "2           0.0              0               0               0  ...   \n",
       "3           1.0              0               0               0  ...   \n",
       "4           0.0              0               0               0  ...   \n",
       "...         ...            ...             ...             ...  ...   \n",
       "5012        0.0              0               0               0  ...   \n",
       "5013        0.0              0               0               0  ...   \n",
       "5014        1.0              0               0               0  ...   \n",
       "5015        0.0              0               0               0  ...   \n",
       "5016        0.0              0               0               0  ...   \n",
       "\n",
       "      sexual_orientation_3.0  sexual_orientation_4.0  sexual_orientation_5.0  \\\n",
       "0                          0                       0                       0   \n",
       "1                          0                       0                       0   \n",
       "2                          0                       0                       0   \n",
       "3                          0                       0                       0   \n",
       "4                          0                       0                       0   \n",
       "...                      ...                     ...                     ...   \n",
       "5012                       0                       0                       0   \n",
       "5013                       0                       0                       0   \n",
       "5014                       0                       0                       0   \n",
       "5015                       0                       0                       0   \n",
       "5016                       0                       0                       0   \n",
       "\n",
       "      smoker  systolic_BP  tot_cholesterol  triglyceride  used_CMH  \\\n",
       "0        0.0    -0.127785         0.957942      0.591330       0.0   \n",
       "1        0.0    -0.346085         1.227433      0.001512       0.0   \n",
       "2        0.0     1.206601         1.031439      0.168181       0.0   \n",
       "3        1.0     0.196809        -0.120023     -0.084354       0.0   \n",
       "4        0.0    -0.673535         0.075970     -0.717249       0.0   \n",
       "...      ...          ...              ...           ...       ...   \n",
       "5012     1.0     0.527114        -0.340516      0.963283       0.0   \n",
       "5013     1.0     0.199665         0.394460      0.171586       0.0   \n",
       "5014     1.0    -0.127785         0.013322     -0.022111       0.0   \n",
       "5015     1.0    -1.874184        -0.879498     -0.424213       0.0   \n",
       "5016     0.0    -1.000984         0.051471     -0.039060       0.0   \n",
       "\n",
       "      vigorous_activity   waist_C  \n",
       "0                   1.0  0.371829  \n",
       "1                   0.0 -0.686526  \n",
       "2                   1.0  2.309155  \n",
       "3                   0.0 -1.033331  \n",
       "4                   0.0 -1.278487  \n",
       "...                 ...       ...  \n",
       "5012                0.0  2.141732  \n",
       "5013                0.0  0.599046  \n",
       "5014                0.0 -0.483226  \n",
       "5015                1.0  0.425643  \n",
       "5016                0.0 -0.889826  \n",
       "\n",
       "[5017 rows x 83 columns]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now lets move on to over-sampling the training data\n",
    "X_train = df_train[features]\n",
    "y_train = df_train[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "smote df    #_ppl_household  #meals_fast_food    BMI       CRP  HIV   age  alcoholic  \\\n",
      "0              2.0          0.953694  26.91  0.150000  0.0  70.0        0.0   \n",
      "1              6.0          1.628220  33.60  0.216375  0.0  47.0        0.0   \n",
      "2              7.0          3.519561  28.40  0.234084  0.0  28.0        0.0   \n",
      "3              1.0          1.441277  30.10  0.364533  0.0  61.0        0.0   \n",
      "4              4.0          1.940883  32.09  0.040085  0.0  62.0        0.0   \n",
      "\n",
      "   annual_HI_1.0  annual_HI_10.0  annual_HI_11.0  ...  sexual_orientation_3.0  \\\n",
      "0              0               1               0  ...                       0   \n",
      "1              0               0               0  ...                       0   \n",
      "2              0               0               0  ...                       0   \n",
      "3              0               0               0  ...                       0   \n",
      "4              0               0               0  ...                       0   \n",
      "\n",
      "   sexual_orientation_4.0  sexual_orientation_5.0  smoker  systolic_BP  \\\n",
      "0                       0                       0     0.0        110.0   \n",
      "1                       0                       0     0.0        126.0   \n",
      "2                       0                       0     0.0         84.0   \n",
      "3                       0                       0     0.0        116.0   \n",
      "4                       0                       0     0.0        124.0   \n",
      "\n",
      "   tot_cholesterol  triglyceride  used_CMH  vigorous_activity     waist_C  \n",
      "0       154.000000     72.000000       0.0                0.0   90.000000  \n",
      "1       193.000000    123.546943       0.0                0.0  106.512331  \n",
      "2       132.000000    112.000000       0.0                0.0   97.600000  \n",
      "3       202.000000     72.000000       0.0                0.0   84.100000  \n",
      "4       186.308425    158.428015       0.0                0.0  107.400000  \n",
      "\n",
      "[5 rows x 83 columns]\n",
      "smote value counts 1.0    18564\n",
      "0.0    18564\n",
      "Name: depressed, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# SMOTE over-sampling\n",
    "import imblearn\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE(random_state=SEED, sampling_strategy='minority')\n",
    "\n",
    "X_sm, y_sm = smote.fit_sample(X_train, y_train)\n",
    "\n",
    "X_sm = pd.DataFrame(X_sm)\n",
    "X_sm.columns = X.keys().tolist()\n",
    "\n",
    "y_sm = pd.DataFrame(y_sm, columns=['depressed'])\n",
    "\n",
    "print('smote df', X_sm.head())\n",
    "print('smote value counts', y_sm.depressed.value_counts())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4065 new random picked points\n",
      "0.0    18564\n",
      "1.0     5569\n",
      "Name: depressed, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# random oversampling\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "ros = RandomOverSampler(sampling_strategy=0.3, random_state=SEED)\n",
    "X_ros, y_ros = ros.fit_sample(X_train, y_train)\n",
    "\n",
    "print(X_ros.shape[0] - X_train.shape[0], 'new random picked points')\n",
    "\n",
    "\n",
    "X_ros = pd.DataFrame(X_ros)\n",
    "X_ros.columns = X_train.keys().tolist()\n",
    "y_ros = pd.DataFrame(y_ros, columns=['depressed'])\n",
    "\n",
    "\n",
    "print(y_ros.depressed.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4065 new random picked points\n",
      "1.0    18481\n",
      "0.0    18481\n",
      "Name: depressed, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# over and undersampling\n",
    "from imblearn.combine import SMOTETomek\n",
    "\n",
    "smt = SMOTETomek(random_state=SEED)\n",
    "X_smt, y_smt = smt.fit_sample(X_train, y_train)\n",
    "\n",
    "print(X_ros.shape[0] - X_train.shape[0], 'new random picked points')\n",
    "\n",
    "\n",
    "X_smt = pd.DataFrame(X_smt)\n",
    "X_smt.columns = X_train.keys().tolist()\n",
    "y_smt = pd.DataFrame(y_smt, columns=['depressed'])\n",
    "\n",
    "\n",
    "print(y_smt.depressed.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling the training over-sampled data\n",
    "X=X_sm.copy()\n",
    "y=y_sm.depressed\n",
    "\n",
    "# scaling the training data\n",
    "X[cont] = ss.fit_transform(X[cont])\n",
    "X_train_sm = X.copy()\n",
    "X_train_sm.columns = X.keys().tolist()\n",
    "\n",
    "# whole data that is SMOTE upsampled and scaled\n",
    "y_train_sm = y.copy()\n",
    "\n",
    "\n",
    "# scaling the training over-sampled data\n",
    "X=X_ros.copy()\n",
    "y=y_ros.depressed\n",
    "\n",
    "# scaling the training data\n",
    "X[cont] = ss.fit_transform(X[cont])\n",
    "X_train_ros = X.copy()\n",
    "X_train_ros.columns = X.keys().tolist()\n",
    "\n",
    "# whole data that is random oversampled and scaled\n",
    "y_train_ros = y.copy()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# scaling the training over-sampled data\n",
    "X=X_smt.copy()\n",
    "y=y_smt.depressed\n",
    "\n",
    "# scaling the training data\n",
    "X[cont] = ss.fit_transform(X[cont])\n",
    "X_train_smt = X.copy()\n",
    "X_train_smt.columns = X.keys().tolist()\n",
    "\n",
    "# whole data that is smotetomek upsampled and scaled\n",
    "y_train_smt = y.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now I have X_train_sm, y_train_sm, X_test, y_test, X_val, y_val all encoded and scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import layers\n",
    "from keras.layers import Activation, Dense, Dropout\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trying different loss function\n",
    "\n",
    "import numpy as np\n",
    "import keras.backend as K\n",
    "\n",
    "def binary_recall_specificity(y_true, y_pred):\n",
    "\n",
    "    TN = np.logical_and(K.eval(y_true) == 0, K.eval(y_pred) == 0)\n",
    "    TP = np.logical_and(K.eval(y_true) == 1, K.eval(y_pred) == 1)\n",
    "\n",
    "    FP = np.logical_and(K.eval(y_true) == 0, K.eval(y_pred) == 1)\n",
    "    FN = np.logical_and(K.eval(y_true) == 1, K.eval(y_pred) == 0)\n",
    "\n",
    "    # Converted as Keras Tensors\n",
    "    TN = K.sum(K.variable(TN))\n",
    "    FP = K.sum(K.variable(FP))\n",
    "\n",
    "    specificity = TN / (TN + FP + K.epsilon())\n",
    "    recall = TP / (TP + FN + K.epsilon())\n",
    "\n",
    "    return recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_loss(recall_weight, spec_weight):\n",
    "\n",
    "    def recall_spec_loss(y_true, y_pred):\n",
    "        return binary_recall_specificity(y_true, y_pred, recall_weight, spec_weight)\n",
    "\n",
    "    # Returns the (y_true, y_pred) loss function\n",
    "    return recall_spec_loss\n",
    "\n",
    "def recall_loss_wrapper():\n",
    "    \"\"\"A wrapper to create and return a function which computes the specificity loss, as (1 - specificity)\n",
    "\n",
    "    \"\"\"\n",
    "    # Define the function for your loss\n",
    "    def recall_loss(y_true, y_pred):\n",
    "        return 1.0 - binary_recall_specificity(y_true, y_pred)\n",
    "\n",
    "    return recall_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_loss = recall_loss_wrapper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting our loss function for specific weights\n",
    "loss = custom_loss(recall_weight=0.9, spec_weight=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def f1(y_true, y_pred, recall_weight, spec_weight):\n",
    "#     y_pred = K.round(y_pred)\n",
    "#     tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
    "#     tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
    "#     fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
    "#     fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
    "\n",
    "#     p = tp / (tp + fp + K.epsilon())\n",
    "#     r = tp / (tp + fn + K.epsilon())\n",
    "#     recall = tf.where(tf.is_nan(r), tf.zeros_like(r), r)\n",
    "#     spec = tf.where(tf.is_nan(s), tf.zeros_like(s), s)\n",
    "#     w = 1.0 - (recall_weight*recall + spec_weight*spec)\n",
    "#     return K.mean(w)\n",
    "\n",
    "def recall_loss(y_true, y_pred, recall_weight, prec_weight):\n",
    "    \n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    recall = tf.where(tf.is_nan(r), tf.zeros_like(r), r)\n",
    "    prec = tf.where(tf.is_nan(p), tf.zeros_like(p), p)\n",
    "    w = 1.0 - (recall_weight*recall + prec_weight*prec)\n",
    "    return 1 - K.mean(w)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our custom loss' wrapper\n",
    "def custom_loss(recall_weight, prec_weight):\n",
    "\n",
    "    def recall_prec_loss(y_true, y_pred):\n",
    "        return recall_loss(y_true, y_pred, recall_weight, prec_weight)\n",
    "\n",
    "    # Returns the (y_true, y_pred) loss function\n",
    "    return recall_prec_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = custom_loss(recall_weight=0.6,prec_weight=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 37128 samples, validate on 5017 samples\n",
      "Epoch 1/10\n",
      "37128/37128 [==============================] - 8s 205us/step - loss: 0.3840 - tp: 14962.0000 - fp: 2555.0000 - tn: 16009.0000 - fn: 3602.0000 - accuracy: 0.8342 - precision: 0.8541 - recall: 0.8060 - auc: 0.9129 - val_loss: 0.2483 - val_tp: 104.0000 - val_fp: 149.0000 - val_tn: 4492.0000 - val_fn: 272.0000 - val_accuracy: 0.9161 - val_precision: 0.4111 - val_recall: 0.2766 - val_auc: 0.7653\n",
      "Epoch 2/10\n",
      "37128/37128 [==============================] - 5s 141us/step - loss: 0.2064 - tp: 16819.0000 - fp: 899.0000 - tn: 17665.0000 - fn: 1745.0000 - accuracy: 0.9288 - precision: 0.9493 - recall: 0.9060 - auc: 0.9695 - val_loss: 0.2297 - val_tp: 58.0000 - val_fp: 50.0000 - val_tn: 4591.0000 - val_fn: 318.0000 - val_accuracy: 0.9266 - val_precision: 0.5370 - val_recall: 0.1543 - val_auc: 0.7677\n",
      "Epoch 3/10\n",
      "37128/37128 [==============================] - 6s 171us/step - loss: 0.1731 - tp: 16933.0000 - fp: 513.0000 - tn: 18051.0000 - fn: 1631.0000 - accuracy: 0.9423 - precision: 0.9706 - recall: 0.9121 - auc: 0.9741 - val_loss: 0.2283 - val_tp: 50.0000 - val_fp: 44.0000 - val_tn: 4597.0000 - val_fn: 326.0000 - val_accuracy: 0.9263 - val_precision: 0.5319 - val_recall: 0.1330 - val_auc: 0.7733\n",
      "Epoch 4/10\n",
      "37128/37128 [==============================] - 5s 146us/step - loss: 0.1587 - tp: 17003.0000 - fp: 345.0000 - tn: 18219.0000 - fn: 1561.0000 - accuracy: 0.9487 - precision: 0.9801 - recall: 0.9159 - auc: 0.9761 - val_loss: 0.2274 - val_tp: 33.0000 - val_fp: 28.0000 - val_tn: 4613.0000 - val_fn: 343.0000 - val_accuracy: 0.9261 - val_precision: 0.5410 - val_recall: 0.0878 - val_auc: 0.7793\n",
      "Epoch 5/10\n",
      "37128/37128 [==============================] - 7s 177us/step - loss: 0.1512 - tp: 17062.0000 - fp: 311.0000 - tn: 18253.0000 - fn: 1502.0000 - accuracy: 0.9512 - precision: 0.9821 - recall: 0.9191 - auc: 0.9773 - val_loss: 0.2268 - val_tp: 25.0000 - val_fp: 21.0000 - val_tn: 4620.0000 - val_fn: 351.0000 - val_accuracy: 0.9259 - val_precision: 0.5435 - val_recall: 0.0665 - val_auc: 0.7834\n",
      "Epoch 6/10\n",
      "37128/37128 [==============================] - 7s 191us/step - loss: 0.1488 - tp: 17033.0000 - fp: 280.0000 - tn: 18284.0000 - fn: 1531.0000 - accuracy: 0.9512 - precision: 0.9838 - recall: 0.9175 - auc: 0.9782 - val_loss: 0.2256 - val_tp: 25.0000 - val_fp: 17.0000 - val_tn: 4624.0000 - val_fn: 351.0000 - val_accuracy: 0.9266 - val_precision: 0.5952 - val_recall: 0.0665 - val_auc: 0.7850\n",
      "Epoch 7/10\n",
      "37128/37128 [==============================] - 5s 144us/step - loss: 0.1456 - tp: 17060.0000 - fp: 264.0000 - tn: 18300.0000 - fn: 1504.0000 - accuracy: 0.9524 - precision: 0.9848 - recall: 0.9190 - auc: 0.9786 - val_loss: 0.2244 - val_tp: 30.0000 - val_fp: 21.0000 - val_tn: 4620.0000 - val_fn: 346.0000 - val_accuracy: 0.9268 - val_precision: 0.5882 - val_recall: 0.0798 - val_auc: 0.7825\n",
      "Epoch 8/10\n",
      "37128/37128 [==============================] - 6s 154us/step - loss: 0.1412 - tp: 17089.0000 - fp: 238.0000 - tn: 18326.0000 - fn: 1475.0000 - accuracy: 0.9539 - precision: 0.9863 - recall: 0.9205 - auc: 0.9798 - val_loss: 0.2267 - val_tp: 27.0000 - val_fp: 18.0000 - val_tn: 4623.0000 - val_fn: 349.0000 - val_accuracy: 0.9268 - val_precision: 0.6000 - val_recall: 0.0718 - val_auc: 0.7834\n",
      "Epoch 9/10\n",
      "37128/37128 [==============================] - 4s 114us/step - loss: 0.1397 - tp: 17091.0000 - fp: 195.0000 - tn: 18369.0000 - fn: 1473.0000 - accuracy: 0.9551 - precision: 0.9887 - recall: 0.9207 - auc: 0.9795 - val_loss: 0.2257 - val_tp: 35.0000 - val_fp: 26.0000 - val_tn: 4615.0000 - val_fn: 341.0000 - val_accuracy: 0.9268 - val_precision: 0.5738 - val_recall: 0.0931 - val_auc: 0.7838\n",
      "Epoch 10/10\n",
      "37128/37128 [==============================] - 8s 217us/step - loss: 0.1368 - tp: 17132.0000 - fp: 202.0000 - tn: 18362.0000 - fn: 1432.0000 - accuracy: 0.9560 - precision: 0.9883 - recall: 0.9229 - auc: 0.9802 - val_loss: 0.2266 - val_tp: 39.0000 - val_fp: 32.0000 - val_tn: 4609.0000 - val_fn: 337.0000 - val_accuracy: 0.9265 - val_precision: 0.5493 - val_recall: 0.1037 - val_auc: 0.7842\n"
     ]
    }
   ],
   "source": [
    "METRICS = [\n",
    "      keras.metrics.TruePositives(name='tp'),\n",
    "      keras.metrics.FalsePositives(name='fp'),\n",
    "      keras.metrics.TrueNegatives(name='tn'),\n",
    "      keras.metrics.FalseNegatives(name='fn'),\n",
    "      keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "      keras.metrics.Precision(name='precision'),\n",
    "      keras.metrics.Recall(name='recall'),\n",
    "      keras.metrics.AUC(name='auc'),\n",
    "]\n",
    "\n",
    "class_weights = {1: 0.85,\n",
    "                0: 0.15}\n",
    "\n",
    "model = keras.Sequential()\n",
    "\n",
    "from keras.optimizers import RMSprop\n",
    "opt = RMSprop()\n",
    "\n",
    "model.add(layers.Dense(64, activation='relu' , input_dim=input_size))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(layers.Dense(64, activation='relu' , input_dim=input_size))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',optimizer=opt,metrics=METRICS)\n",
    "\n",
    "history = model.fit(X_train_sm, y_train_sm, validation_data=(X_val, y_val),epochs=10, batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6272/6272 [==============================] - 1s 127us/step\n",
      "Test loss: 0.24341818477426255\n",
      "Test accuracy: 0.9207589030265808\n",
      "Test precision: 0.37142857909202576\n",
      "Test recall: 0.08297872543334961\n",
      "Test F1-score: 0.08297872543334961\n",
      "Test auc: 0.7641918063163757\n",
      "Test TP: 39.0\n",
      "Test FP: 66.0\n",
      "Test TN: 5736.0\n",
      "Test FN: 431.0\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test, batch_size=128)\n",
    "\n",
    "f1 = 2*((score[6]*score[7])/(score[6]+score[6]))\n",
    "\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[5])\n",
    "print('Test precision:', score[6])\n",
    "print('Test recall:', score[7])\n",
    "print('Test F1-score:', f1)\n",
    "print('Test auc:', score[8])\n",
    "print('Test TP:', score[1])\n",
    "print('Test FP:', score[2])\n",
    "print('Test TN:', score[3])\n",
    "print('Test FN:', score[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=KNeighborsClassifier(),\n",
       "             param_grid={'n_neighbors': array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "       18, 19, 20, 21, 22, 23, 24]),\n",
       "                         'weights': ['uniform', 'distance']})"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets try KNN\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#create new a knn model\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "#create a dictionary of all values we want to test for n_neighbors\n",
    "param_grid = {\"n_neighbors\": np.arange(1, 25), 'weights':['uniform', 'distance']}\n",
    "\n",
    "#use gridsearch to test all values for n_neighbors\n",
    "knn_gscv = GridSearchCV(knn, param_grid, cv=5)\n",
    "\n",
    "#fit model to data\n",
    "knn_gscv.fit(X_sm, y_sm.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5802    0]\n",
      " [ 470    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      1.00      0.96      5802\n",
      "         1.0       0.00      0.00      0.00       470\n",
      "\n",
      "    accuracy                           0.93      6272\n",
      "   macro avg       0.46      0.50      0.48      6272\n",
      "weighted avg       0.86      0.93      0.89      6272\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "y_pred = knn_gscv.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=RandomForestClassifier(class_weight='balanced'),\n",
       "             param_grid={'min_samples_leaf': [1, 20, 100],\n",
       "                         'min_samples_split': [2, 20, 100]})"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# try RF\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# The grids for min_samples_split\n",
    "min_samples_split_grids = [2, 20, 100]\n",
    "\n",
    "# The grids for min_samples_leaf\n",
    "min_samples_leaf_grids = [1, 20, 100]\n",
    "\n",
    "\n",
    "param_grids = {'min_samples_split': min_samples_split_grids,\n",
    "                       'min_samples_leaf': min_samples_leaf_grids}\n",
    "\n",
    "rf = RandomForestClassifier(class_weight='balanced')\n",
    "\n",
    "#use gridsearch to test all values for n_neighbors\n",
    "rf_gscv = GridSearchCV(rf, param_grids, cv=5)\n",
    "\n",
    "#fit model to data\n",
    "rf_gscv.fit(X_sm, y_sm.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5800    2]\n",
      " [ 470    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      1.00      0.96      5802\n",
      "         1.0       0.00      0.00      0.00       470\n",
      "\n",
      "    accuracy                           0.92      6272\n",
      "   macro avg       0.46      0.50      0.48      6272\n",
      "weighted avg       0.86      0.92      0.89      6272\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = rf_gscv.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
